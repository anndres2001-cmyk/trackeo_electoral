import pandas as pd               # manejo de Tablas (DataFrames). Matemáticamente son Matrices.
import numpy as np                # cálculo numérico, maneja vectores y matrices rápidas.
import matplotlib.pyplot as plt   # librería base para graficar (Ejes, Figuras).
import matplotlib.ticker as mtick # herramienta para formatear ejes (ej: poner el signo %).
import os                         # "Operating System". Permite crear carpetas y guardar archivos en tu PC.
import geopandas as gpd
import seaborn as sns

os.environ["OGR_GEOJSON_MAX_OBJ_SIZE"] = "0"  #Le pedimos al sistema que confíe y cargue el archivo de IGN completo por más pesado que sea.

# Librerías de Inteligencia Artificial (Scikit-Learn)
from sklearn.experimental import enable_iterative_imputer  # Habilita el MICE (aún es experimental en sklearn).
from sklearn.impute import IterativeImputer                # El algoritmo MICE para llenar datos faltantes.
from sklearn.linear_model import LinearRegression          # Usado por MICE para adivinar números.
from sklearn.linear_model import LogisticRegression        # Usado para predecir Voto (Sí/No).

#CARGAMOS MAPA
def cargar_mapa_ign():
    print("Cargando mapa 'provincias.json'...") #función para buscar el archivo provincia.json en la carpeta -> datos de las IGN

    try:
        gdf = gpd.read_file("provincias.json")   # Normalizamos nombre del mapa
        col_nom = next((c for c in gdf.columns if c.lower() in ['nam','fna','nombre']), None)

        if col_nom:	#Normaliza nombre de columnas
            gdf['geo_key'] = gdf[col_nom].astype(str).str.strip().str.lower() #se crea un nuevo diccionario con columnas que normaliza todo y permite concatenar los estratos.

            gdf['geo_key'] = gdf['geo_key'].replace({
                'ciudad autónoma de buenos aires': 'caba', 'capital federal': 'caba',
                'tierra del fuego, antártida e islas del atlántico sur': 'tierra del fuego'
            })

            return gdf # finaliza la ejecución de la función y devuelve el dt limpio 

    except: pass
    return None

### SELECCIONAR CANDIDATO

def listar_y_elegir(lista_opciones, mensaje="Seleccioná una opción"): #de forma numerica elegimos al candidato a traves de la funcion "listar_y_elegir". recibe una lista de opciones y un mensaje opcional que se muestra como título del menú.
    print(f"\n--- {mensaje} ---")                  # Imprime el título del menú.
    for i, op in enumerate(lista_opciones):       # Recorre la "lista_opciones" con enumarate(), indexando el conjunto de opciones (0, 1, 2...).
        if isinstance(op, tuple):                 # Si es tupla muestra solo el nombre
            print(f"[{i}] {op[0]}")               # ... muestra solo el primer nombre.
        else:
            print(f"[{i}] {op}")                  # sino, muestra la opción tal cual.
    
    while True:                                   # bucle infinito: no sale hasta que el usuario escriba bien (return)
        try:
            inp = input("Ingrese el número: ")    # pide el dato al usuario.
            idx = int(inp)                        # Intenta convertir ese string a numero entero
            
            if 0 <= idx < len(lista_opciones):    # Lógica Booleana: Verifica si el número está dentro del rango de la lista. #el indice dentro de a logica
                val = lista_opciones[idx]         # recuperando el objeto real de la lista.
                return val[0] if isinstance(val, tuple) else val # Devuelve el valor limpio.
            
            print("EROR.")      # Si el número es muy alto o negativo.
        except ValueError:
            print("ERROR. Por favor, escribime un numero válido.") # Si escribió letras en vez de números.

# LIMPIEZA
def preparar_base(df_raw): #vamos a usar el CSV como base cruda #vamos a normalizar los nombres de las columnas #eliminamos filas que no sirvan (sin fecha o voto)
    df = df_raw.copy() # creamos una copia en memoria para no romper el original df_raw.copy()
    df.columns = (df.columns.str.strip().str.lower() # .str.strip(): Saca espacios a los costados. # .str.lower(): Pasa todo a minúsculas.
                  .str.replace(r"[^a-z0-9_ ]", "", regex=True)
                  .str.replace(r"\s+", "_", regex=True)) # eeemplaza espacios internos por guion bajo. # regex r"[^a-z0-9_ ]": "Si NO es letra, número o guion bajo, bórralo".
    
    cols = df.columns                                     # Guarda la lista de nombres limpios.
    print("\nDIAGNÓSTICO DE COLUMNAS")

    try:                                                                                                   # con "try" iniciamos un bloque que atrapará errores si falta alguna columna.
        c_fecha = [c for c in cols if "fecha" in c or "date" in c or "time" in c][0]                       # busca columna que tenga "fecha", "date" o "time". Toma la primera [0].
        c_id = [c for c in cols if ("ident" in c or "id_" in c or "encuesta" in c) and "fecha" not in c][0] # usca ID: debe decir "id" o "encuesta" PERO NO "fecha" (Lógica: A y No B).
        c_estrato_list = [c for c in cols if "estrato" in c or "socio" in c]                                # busca Estrato: puede no existir, por eso chequeamos si la lista está vacía al final.
        c_estrato = c_estrato_list[0] if c_estrato_list else None                                           # busca posibles columnas de estrato; puede haber 0 o más.
        c_sexo = [c for c in cols if "sexo" in c or "genero" in c][0]                                         
        c_edad = [c for c in cols if "edad" in c or "anos" in c][0]
        c_educ = [c for c in cols if "educ" in c or "nivel" in c or "instruccion" in c][0]
        c_hogar = [c for c in cols if "integrantes" in c or "hogar" in c or "personas" in c][0]
        c_imagen = [c for c in cols if "imagen" in c][0]
        c_voto = [c for c in cols if "voto" in c and "anterior" not in c][0]                                  # en caso de voto elegimos que no sea "anterior"
        c_voto_ant = [c for c in cols if "anterior" in c][0]

        col_map = {                                                                                            #a las busquedas de nombres las pusimos dentro de un diccionario para poder integrarlas mejor y cambiarles el nombre
            c_fecha: "fecha", c_id: "encuesta", c_sexo: "sexo", c_edad: "edad",
            c_educ: "nivel_educativo", c_hogar: "integrantes_h", c_imagen: "imagen_candidato",
            c_voto: "voto", c_voto_ant: "voto_anterior"
        }
        if c_estrato: col_map[c_estrato] = "estrato" #solo renombra estrato si existe.

        print(f"Columnas identificadas")
    except IndexError:                                                                                         # Si alguna lista [c for c...] quedó vacía, [0] significa que da ERROR, por lo tanto, que imprima error
        raise ValueError("ERROR: faltan columnas obligatorias en el CSV.")

    df = df.rename(columns=col_map) # aplica los renombres definidos en col_map. ACA SE ESTANDARIZAN las variables para el resto del pipeline.
    vars_txt = ["estrato", "sexo", "nivel_educativo", "voto", "voto_anterior"]                                  

# Crea una lista que contiene los nombres estandarizados de todas las variables categóricas que necesitan una limpieza especial.

    for col in vars_txt:                                                                                        # Recorremos una por una todas esas columnas. Inicia un bucle que iterará sobre cada nombre de columna en la lista vars_txt

        if col in df.columns:                                                                                    # verificamos que la columna exista realmente en el DataFrame.
            df[col] = df[col].astype(str).str.strip().str.lower().replace(["nan", "none", "null", "", " "], np.nan) ##las estandariza y al resto las vuelve NaN

    vars_num = ["edad", "integrantes_h", "imagen_candidato"]                                                      # a las Variables numérica las forzamos a número. 'errors="coerce"' convierte errores en NaN (Vacío).
    for col in vars_num:                                                                                         # Lista de columnas numéricas que pueden venir mal cargadas.
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    criticas = ["fecha", "encuesta", "integrantes_h", "imagen_candidato", "voto", "voto_anterior"]              # # Si falta fecha, voto o imagen, la encuesta no sirve. Se elimina la fila.
    criticas_reales = [c for c in criticas if c in df.columns]                                                  # Filtramos solo las que existen en "criticas" a "critical_reales"
    
    n_antes = len(df)                                                                                           # guardamos las filas en una variable n_antes , antes de eliminarlas
    df = df.dropna(subset=criticas_reales)                                                                       # Drop NaN (Borrar Nulos). Elimina filas inservibles: sin fecha, sin voto, sin imagen, etc.
    print(f"Se eliminaron {n_antes - len(df)} filas por falta de datos")

    if "imagen_candidato" in df.columns: df["imagen_candidato"] = df["imagen_candidato"].clip(0, 100)            # si la imagen del candidato existe entonces las ajustamos a 0 o 100 si pasa alguna de las dos. Función Clip. f(x) = min(max(x, 0), 100).
    
#AGREGADO MAPAS:
    if "estrato" in df.columns:   # Limpieza base
        df["estrato"] = df["estrato"].str.lower().str.strip()  # Diccionario para unificar tus nombres con el IGN
        dicc_ign = {
            "primer cordon": "provincia de buenos aires", "segundo cordon": "provincia de buenos aires",
            "tercer cordon": "provincia de buenos aires", "conurbano": "provincia de buenos aires",
            "capital federal": "caba", "capital": "caba",
            "cordoba": "provincia de córdoba", "tucuman": "provincia de tucumán",
            "entre rios": "provincia de entre ríos", "neuquen": "provincia del neuquén",
            "rio negro": "provincia de río negro", "misiones": "provincia de misiones",
            "chaco": "provincia del chaco", "corrientes": "provincia de corrientes"
                    }
        df["estrato_mapa"] = df["estrato"].replace(dicc_ign)
        mask = ~df["estrato_mapa"].str.contains("provincia", na=False) & (df["estrato_mapa"]!="caba")
        df.loc[mask, "estrato_mapa"] = "provincia de " + df.loc[mask, "estrato_mapa"]

    return df

def unificar_sexo(df):                                                                                          # vamos a detectar las columnas de sexo y sus derivados: generando sexo_mas_unificado y sexo_fem_unificado
    df_out = df.copy() ## Busca todas las columnas que empiecen con 'sexo_'
    cols_sexo = [c for c in df_out.columns if c.startswith("sexo_")]                                       #buscamos todas las columnas que empiecen por sexo
    cols_fem = [c for c in cols_sexo if "fem" in c or "mujer" in c or c.endswith("_f")]                   #filtramos por palabras claves entre los "sexo"
    cols_masc = [c for c in cols_sexo if "masc" in c or "hombre" in c or c.endswith("_m")]

    if cols_fem:
        df_out["sexo_femenino_unificado"] = df_out[cols_fem].sum(axis=1).clip(0, 1)                 #si tenía sexo_fem=1 y sexo_mujer=0 → 1. si tenía errores tipo 1 y 1 → queda 2 → clip(0,1) lo baja a 1.
        df_out = df_out.drop(columns=cols_fem)                                                      # Borra las originales para no duplicar.
    if cols_masc:
        df_out["sexo_masculino_unificado"] = df_out[cols_masc].sum(axis=1).clip(0, 1)
        df_out = df_out.drop(columns=cols_masc)
    return df_out

def imputar_datos(df_limpio):  # ahora que tenemos las columnas vamos a IMPUTAR con MICE que utiiliza las relaciones matematicas entre variables para estimar los valores faltantes.
    #columnas categoricas

    df = df_limpio.copy()                                                                          # hacemos una copia del DF
    cols_cat = [c for c in ["estrato", "sexo", "nivel_educativo"] if c in df.columns]               # Elegimos qué variables categóricas vamos a usar para ayudar a la predicción.
    if "voto" in df.columns: df = pd.get_dummies(df, columns=["voto"], dummy_na=False)               ## # BINARIZAMOS "voto" y "voto_anterior"(One-Hot Encoding) para que el modelo 'vea' a quién vota la gente. # y use eso para predecir su estrato/edad faltante.
    if "voto_anterior" in df.columns: df = pd.get_dummies(df, columns=["voto_anterior"], dummy_na=False)

    # Binarizamos las demográficas faltantes
    df_encoded = pd.get_dummies(df, columns=cols_cat, dummy_na=False)
    
    # Algoritmo MICE:
    # Itera (repite) regresiones lineales.
    # Primero: rellena con el promedio.
    # Segundo: predice Edad usando (Voto + Estrato). Actualiza Edad.
    # Tercero: predice Estrato usando (Voto + Edad nueva).
    # ... Repite 20 veces (max_iter) hasta que los números se estabilizan (convergen).
    imputer = IterativeImputer(estimator=LinearRegression(), max_iter=20, random_state=42, min_value=0) # creamos el objeto MICE que imputará los valores faltantes usando regresiones lineales iteradas. 
    
    
    cols_si = [c for c in df_encoded.columns if c not in ["fecha", "encuesta", "estrato_mapa"]]    # celeccionamos todas las columnas numéricas excepto los IDs y Fechas (que no tienen correlación matemática útil).
    if cols_si:
        try:    #Abre bloque seguro para ejecutar el imputador sin romper el programa si falla.
            df_encoded[cols_si] = imputer.fit_transform(df_encoded[cols_si])     ## ajusta regresiones internas y rellena todos los valores faltantes. El imputador devuelve una matriz numérica completa
            if "edad" in df_encoded.columns: df_encoded["edad"] = df_encoded["edad"].round().astype(int) # Si la columna “edad” existe luego del proceso entonces redondeo: La edad estimada puede ser 34.6 años -> pasamos a 35.
        except: 
            pass # si falla (ej: matriz vacía), devolvemos como estaba.
        
    return df_encoded

# Graficos

def graficar_estilo_premium(df, col_x, col_y=None, col_grupo=None, estilo=1, gdf_mapa=None):    # ahora GRAFICOS usando matplotlib. DF: tabla de graficos. col x/ col_y
    plt.style.use('seaborn-v0_8-whitegrid')                                      # configuramos estética (fondo blanco con grilla suave).
    
    if estilo == 1: # Histograma con la mediana
        variable = df[col_x].dropna() # Limpiamos los nulos para evitar errores
        mediana = variable.median()
        
        plt.figure(figsize=(10, 6))
        plt.hist(variable, bins=20, edgecolor="black", color="#69b3a2", alpha=0.7, label="Frecuencia")
        plt.axvline(mediana, color='#d62728', linestyle='dashed', linewidth=2, label=f'Mediana: {mediana:.1f}') 
        plt.title(f"Distribución de {col_x}", fontsize=15, fontweight='bold')
        plt.ylabel("Cantidad de Casos")
        plt.xlabel(col_x)
        plt.legend() # Muestra la etiqueta de la mediana
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout(); plt.show()

   elif estilo == 2 and col_y: # Scatter con Línea de Tendencia
        # Limpiamos datos para cálculo matemático
        data = df[[col_x, col_y]].dropna()
        x = data[col_x]
        y = data[col_y]
        plt.figure(figsize=(10, 6))
        plt.scatter(x, y, alpha=0.5, color="#4c72b0", label="Casos")
        # CÁLCULO DE TENDENCIA (y = mx + b)
        if len(x) > 1:
            m, b = np.polyfit(x, y, 1) # Ajuste lineal
            plt.plot(x, m*x + b, color='#d62728', linewidth=2, label=f'Tendencia')
        plt.title(f"Correlación: {col_x} vs {col_y}", fontsize=15, fontweight='bold')
        plt.xlabel(col_x); plt.ylabel(col_y)
        plt.legend()
        plt.tight_layout(); plt.show()

  elif estilo == 3 and col_y and col_grupo: # Scatter con Centroides
        grupos = df[col_grupo].dropna().unique()
        colores = plt.cm.tab10(np.linspace(0, 1, len(grupos)))
        mapa_col = {g: colores[i] for i, g in enumerate(grupos)}
        plt.figure(figsize=(11, 7))
        # 1. Dibujamos los puntos (Fondo)
        for g in grupos:
            subset = df[df[col_grupo] == g]
            plt.scatter(subset[col_x], subset[col_y], c=[mapa_col[g]], alpha=0.3, s=30) # Puntos chicos y transparentes
            # 2. Dibujamos el CENTROIDE (Punto Gordo Promedio)
            centro_x = subset[col_x].mean()
            centro_y = subset[col_y].mean()
            plt.scatter(centro_x, centro_y, c=[mapa_col[g]], s=200, edgecolor='black', marker='X', label=f"{g} (Promedio)")
        plt.title(f"Segmentación: {col_x} vs {col_y} por {col_grupo}", fontsize=15, fontweight='bold')
        plt.xlabel(col_x); plt.ylabel(col_y)
        plt.legend(title="Promedios por Grupo", bbox_to_anchor=(1.05, 1), loc='upper left') # Leyenda afuera
        plt.tight_layout(); plt.show()

    elif estilo == 4 and col_y:                                                              # 4- BOXPLOT: elegir variable numerica (Y) y categoricas(X).
        orden = sorted(df[col_x].unique().astype(str))                                       # Ordena las categorías del eje X alfabéticamente.
        datos = [df.loc[df[col_x].astype(str)==c, col_y].values for c in orden]              # crea una lista de cada categoria uno por cada categoría.
        plt.figure(figsize=(12, 7))

        bp = plt.boxplot(datos, tick_labels=orden, patch_artist=True, showmeans=True,             # Guardamos el gráfico en una variable 'bp' para poder pintarlo después
                         medianprops=dict(color="#d62728", linewidth=2),                     # configuración de líneas: Mediana roja, Media (triángulo) amarilla
                         meanprops=dict(marker='^', markerfacecolor='yellow', markeredgecolor='black'),
                         boxprops=dict(color="black", linewidth=1.5))

        colores = plt.cm.Set2(np.linspace(0, 1, len(datos)))                                 # coloreado inteligente (Una paleta distinta para cada caja)
        for patch, color in zip(bp['boxes'], colores):
            patch.set_facecolor(color)
            patch.set_alpha(0.6)                                                             # Transparencia para ver la grilla de fondo
  
        for i, d in enumerate(datos, start=1):                                              # jitter (Ruido): Agrega puntos dispersos aleatoriamente sobre el eje X para mostrar densidad.
            x = np.random.normal(i, 0.04, size=len(d))                                      # np.random.normal(i, 0.04): Centrado en la categoría 'i' con desviación 0.04.
            plt.plot(x, d, 'o', alpha=0.3, color="black", markersize=3)

            top_val = np.max(d) if len(d) > 0 else 0                                        # poner el "N=" arriba de cada caja
            plt.text(i, top_val * 1.02, f'n={len(d)}', 
                     ha='center', va='bottom', fontsize=9, fontweight='bold', color='#333')
            
        plt.title(f"Distribución: {col_y} por {col_x}", fontsize=16, fontweight='bold')
        plt.grid(axis='y', linestyle='--', alpha=0.4)
        plt.xticks(rotation=45 if len(orden) > 4 else 0)                                     # rotamos las etiquetas si son muchas para que se lean bien
        plt.tight_layout()
        plt.show()

elif estilo == 5 and col_y:                                                             # 5. BARRAS
        resumen = df.groupby(col_x)[col_y].agg(['mean', 'std', 'count']).sort_index()       # calculamos Promedio (mean) Y Desvío Estándar (std) al mismo tiempo
        resumen['se'] = resumen['std'] / np.sqrt(resumen['count'])                          # Calculamos el error estándar (para el intervalo de confianza básico)
        plt.figure(figsize=(12, 6))
        
        ax = resumen['mean'].plot(kind='bar', yerr=resumen['se'], capsize=5,               # 2. Dibujamos con yerr (Y-Error) que son los "bigotes" negros                              # capsize=5 pone los techitos en los bigotes
                                  color="#c44e52", alpha=0.9, edgecolor='black', rot=45)

        plt.title(f"Promedio de {col_y} por {col_x} (con error estándar)", fontsize=15, fontweight='bold')
        plt.ylabel(f"Promedio estimado")
        plt.grid(axis='y', linestyle='--', alpha=0.3)

        for p in ax.patches:                                                                  # recorre y coloca una etiqueta de Valor encima de las barras
            ax.annotate(f"{p.get_height():.1f}",                                              # Escribimos el número formateado (ej: 45.2) arriba de la barra
                        (p.get_x() + p.get_width() / 2., p.get_height()), 
                        ha='center', va='bottom', xytext=(0, 5), 
                        textcoords='offset points', fontweight='bold')

        plt.tight_layout()
        plt.show()

   elif estilo == 6 and col_y:                                                              # 6. LÍNEAS. perfecto para mostrar tendencias, evoluciones o comportamientos. por ejemplo, cuanto cambia la probabilidad de voto dependiendo de alguna situacion del encuestado
        data_agg = df.groupby(col_x)[col_y].mean().sort_index()                              # Agregación por promedio.
        plt.figure(figsize=(12, 6))
        plt.plot(data_agg.index, data_agg.values, marker='o', markersize=8,                   # dibujamos la línea (más gruesa y con marcadores sólidos)
                 linewidth=3, color="#4c72b0", label=col_y)
        for x, y in zip(data_agg.index, data_agg.values):                                     # scribir el valor en cada punto

            texto = f"{y:.1f}%" if y > 1 else f"{y:.2f}"                                     # Formato: si es chico (0.45) lo muestra como porcentaje, si es grande (45) como entero
            if "probabilidad" in col_y or "imagen" in col_y: 
                 texto = f"{y:.1f}%" # Forzamos % si es probabilidad

            plt.annotate(texto, 
                         (x, y), 
                         textcoords="offset points", 
                         xytext=(0, 10), # 10 pixeles arriba del punto
                         ha='center', 
                         fontweight='bold',
                         fontsize=10,
                         bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8)) 
                         # La cajita blanca de fondo para que se lea siempre

        plt.title(f"Evolución: {col_y} según {col_x}", fontsize=16, fontweight='bold')
        plt.ylabel("Valor Promedio")
        plt.grid(True, linestyle='--', alpha=0.3) # Grilla muy suave
        plt.tight_layout()
        plt.show()

elif estilo == 7 and gdf_mapa is not None:                                             # 7. MAPA

        print(f"Generando mapa para: {col_x}")

        if "estrato_mapa" not in df.columns:
            print("No existe columna 'estrato_mapa'.")
            return
        
        # Promedios por provincia
        datos = df.groupby("estrato_mapa")[col_x].agg(["mean", "count"]).reset_index()
        datos.rename(columns={"mean": "valor_medio", "count": "n"}, inplace=True)

        # Unimos con el shapefile
        final = gdf_mapa.merge(datos, left_on="geo_key", right_on="estrato_mapa", how="left")
        print("\nPequeño diagnóstico territorial previo al mapa")
        print("------------------------------------------")

        datos_validos = datos.dropna(subset=["valor_medio"])

        # Top 3
        top3 = datos_validos.sort_values("valor_medio", ascending=False).head(3)
        print("\n3 provincias con mayor valor promedio:")
        print(top3[["estrato_mapa", "valor_medio", "n"]].to_string(index=False))

        # Bottom 3
        bottom3 = datos_validos.sort_values("valor_medio").head(3)
        print("\n3 provincias con menor valor promedio:")
        print(bottom3[["estrato_mapa", "valor_medio", "n"]].to_string(index=False))

        # Gráfico del mapa mejorado
        fig, ax = plt.subplots(1, 1, figsize=(10, 12))
final.plot(
            column="valor_medio",
            cmap='OrRd',
            ax=ax,
            edgecolor='gray',
            legend=True,
            vmin=datos_validos["valor_medio"].min(),
            vmax=datos_validos["valor_medio"].max(),
            missing_kwds={
                'color': '#f0f0f0',
                'hatch': '///',
                'label': 'Sin datos'
            }
        )

        plt.axis('off')
        plt.title(f"Mapa: {col_x} por provincia\n(promedio)", fontsize=16)
        plt.show()

# Ejecucucion
if __name__ == "__main__":                                                             # Garantiza que el código SOLO se ejecuta si corrés el archivo directamente (no si lo importás).
    entrada = input("Ingresa el nombre del archivo: ").strip()
    ARCHIVO = entrada                                                          # Definir nombre del archivo (Cambiar si usás otro CSV).
    
    try:                                                                               #Inicia bloque
        print("¡HOLA GRUPO! Estoy procesando datos del CSV...")
        
        # 1. CARGA
        df_raw = pd.read_csv(ARCHIVO)     # Lee CSV del disco y llamamos a TODAS las funciones
        df_clean = preparar_base(df_raw)  # Limpia nombres y nulos.
        df_full = imputar_datos(df_clean) # Rellena datos faltantes con IA.
        df_full = unificar_sexo(df_full)  # Arregla dummies de sexo.
        
        gdf_argentina = cargar_mapa_ign() 

        if "estrato_mapa" in df_clean.columns: 
            df_full["estrato_mapa"] = df_clean["estrato_mapa"]

        # 2. SELECCIÓN DE OBJETIVO (A QUIÉN QUEREMOS PREDECIR)  # filtra columnas que sean de voto actual.
        cols_voto = [c for c in df_full.columns if "voto_" in c and "anterior" not in c] # agarra todas las columnas de voto actual (voto_a, voto_b, voto_c, etc.). Descarta las de voto anterior.
        col_target = listar_y_elegir(cols_voto, "¿A quien queres trackear?") # Muestra menú interactivo y el usuario elige qué candidato quiere modelar.

        # 3. MODELADO LOGÍSTICO (REGRESIÓN)
        ### fecha → no predice
        ### encuesta (ID) → ruido
        ### el propio col_target → escaparía fuga de datos
        ### otros "voto" actuales → también fuga de datos.
        
        excluir = ["fecha","encuesta", "estrato_mapa", col_target] + [c for c in df_full.columns if "voto_" in c and c!=col_target]  ## definimos las variables que queremos excluir de para graficar. X (predictoria) e Y (objetivo)
        X = df_full.drop(columns=excluir, errors='ignore')  # indepdencia necesaria para elegir que variables predecir       # Excluimos 'fecha' y 'encuesta' (no predicen) y el propio voto para no hacer trampa.
        Y = df_full[col_target]                                                                                      ## pero las agregamos aca. 
        
        # 3.2 Entrenamos el modelo logístico. # es la Instancia del modelo "Logit". max_iter=1000 evita problemas de convergencia.
        model = LogisticRegression(max_iter=1000)     # Ecuación: P(Voto) = 1 / (1 + e^-(B0 + B1*Edad + B2*Estrato...))
        model.fit(X, Y)                                ## Ajusta la regresión logística usando todas las filas completas.
        
        
        df_full["probabilidad_voto"] = model.predict_proba(X)[:, 1] * 100   ## # Creamos la variable 'Probabilidad de Voto' (0 a 100) para usar en gráficos.  #aplica la sigmoide #convierte probabilidad a porcentaje
        

        # Extraemos los Coeficientes (Betas) de la regresión. # coeficiente positivo: Aumenta chance de voto. # negativo: Disminuye.
        coefs = pd.DataFrame({"Variable": X.columns, "Peso": model.coef_[0]})   ## extrae los coeficientes, es decir las BETAS (b0 b1, ...) cada columna X elegida.... dentro del DF para ponerlo dentro de "coefs"
        coefs["Impacto_Absoluto"] = coefs["Peso"].abs() #                        # vamos a medir el impacto absoluto de cada coefs y los valores absolutos de su PESO en la variable elegida
        top_5 = coefs.sort_values("Impacto_Absoluto", ascending=False).head(5)    # mostramos los primeros 5 #ordena con sort.values() dentro de "top_5"
        
        print(f"\n Los cinco coeficientes que mas influyen: {col_target.upper()}")
        print(top_5[["Variable", "Peso"]].to_string(index=False))
        print("------------------------------------------------------------------\n")

        # Elegir tracking tempral (rolling window mean())
        print("\n GENERANDO TRACKING TEMPORAL...")
        
        # 1. Preparamos los datos: copiamos solo lo necesario
        df_track = df_full[["fecha", "encuesta", col_target]].copy()

        # 2. Aseguramos que la fecha sea cronológica (Matemática: Ordenamiento Temporal)
        df_track["fecha"] = pd.to_datetime(df_track["fecha"], format="mixed", dayfirst=False)
        df_track = df_track.set_index("fecha").sort_index()
        
        # 3. Menú para elegir la ventana (El "N" del promedio)
        ventana_str = listar_y_elegir(["Semanal (7D)", "Mensual (30D)", "Trimestral (90D)"], "Elegí ventana de suavizado")
        ventana = "90D" if "90" in ventana_str else "30D" if "30" in ventana_str else "7D"
        
        # 4. Cálculo Matemático: Media Móvil Simple (SMA)
        # Formula: Promedio de los puntos entre (t) y (t - ventana)
        df_track["media_movil"] = df_track[col_target].rolling(ventana).mean()
        
        # 5. Gráfico
        plt.figure(figsize=(10, 5))
        ax = df_track["media_movil"].plot(linewidth=2.5, color="#d62728")
        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0)) # Eje Y en %
        plt.title(f"Evolución Intención de Voto: {col_target.upper()} ({ventana})", fontsize=14)
        plt.grid(True, linestyle="--", alpha=0.5); plt.tight_layout(); plt.show()
        

         print("Un segundo que estamos Guardando archivos...") 


        # A) Guardar la Base Final Completa
        df_full.to_csv("base_final_procesada.csv", index=False)         #al DF #df_full" la guardamos en un CSV
        print("   -> 'base_final_procesada.csv' guardado.")
        
        # B) Guardar CSVs Binarizados (Tracking)
        os.makedirs("archivos_tracking", exist_ok=True)            # crea una carpeta en tu servidor
        
        
       # B) Guardar CSVs Binarizados (Tracking) - VERSIÓN BLINDADA
        os.makedirs("archivos_tracking", exist_ok=True)
        
        # Limpieza profunda de nombres de columna por si las dummies generaron basura
        df_full.columns = (df_full.columns.str.replace(r"[^a-z0-9_]", "", regex=True))
        
        cols_bin = [c for c in df_full.columns if df_full[c].nunique()<=2 and c not in ["fecha","encuesta"]]
        
        for col in cols_bin:
            # Sanitización: Elimina caracteres prohibidos en nombres de archivo de Windows
            nombre_limpio = col.replace("?", "").replace("/", "").replace("\\", "")
            try:
                df_full[["fecha","encuesta",col]].to_csv(f"archivos_tracking/tracking_{nombre_limpio}.csv", index=False)
            except OSError:
                print(f"ESPERA: No se pudo guardar '{col}' por caracteres inválidos.")
        
        print(f"TMAP! Archivos guardados en carpeta 'archivos_tracking'.")

        # MENÚ INTERACTIVO DE GRÁFICOS
        vars_disp = [c for c in df_full.columns if c not in ["fecha", "encuesta"]]             ## Quita columnas que no sirven para gráficos estadísticos.
        v_num = [c for c in vars_disp if df_full[c].nunique() > 5]                            # Numéricas (muchos valores). ## Sirve para SCATTER, HISTOGRAMAS, LINEAS, REGRESION VISUAL
        posibles_cat = ["estrato", "sexo", "nivel_educativo", "voto", "voto_anterior"]        # CORRECCIÓN: Definimos las categóricas explícitamente buscando en df_clean # Esto asegura que aparezcan "estrato", "sexo", "nivel_educativo"
        v_cat_reales = [c for c in posibles_cat if c in df_clean.columns]                     # Categóricas (pocos valores). ## Sirve para BOXPLOT, BARRAS, COMPARACIONES POR GRUPO

        v_cat = v_cat_reales

        while True:                                                                   ## CONTINUA EL MENU INTERACTIVO con los nombres de las opciones
            opciones_menu = [
                ("Salir", "Cierra el programa."),
                ("Histograma", "Ver distribución de 1 variable."),
                ("Scatter Simple", "Correlación entre 2 variables numéricas."),
                ("Scatter con Color", "Correlación pintada por grupo."),
                ("Boxplot Premium", "Comparar Categórica vs Numérica."),
                ("Gráfico de Barras", "Comparar Promedios entre Grupos."),
                ("Gráfico de Líneas", "Ver Tendencia continua."),
                ("MAPA ARGENTINA", "Ver mapa geográfico."), # <--- AGREGAR
            ]
            opcion = listar_y_elegir(opciones_menu, "¿Qué gráfico querés hacer?")                           # Minimiza error humano
            
            if opcion == "Salir": break                                                                # Si elige salir [0], BREAK
            
            # Lógica de ruteo: según la opción, llama a la función graficar con los parámetros correctos.
            if "Histograma" in opcion:                                                                 #Le pide al usuario elegir una variable (numérica).
                graficar_estilo_premium(df_full, listar_y_elegir(vars_disp, "Variable"), estilo=1)     # Llama a la función graficar_estilo_premium con estilo=1. Histograma = Frecuencia absoluta por intervalo


            elif "Scatter Simple" in opcion:                                                                 #
                graficar_estilo_premium(df_full, listar_y_elegir(v_num, "Eje X"), listar_y_elegir(v_num, "Eje Y"), estilo=2) #una variable para X #una variable para Y #Grupo para colorear
            
            elif "Scatter con Color" in opcion:
                # CORRECCIÓN: Usamos df_clean para buscar las etiquetas de texto originales
                cols_color = [c for c in df_clean.columns if c in v_cat] + [c for c in df_full.columns if "sexo_" in c]
                cx = listar_y_elegir(v_num, "Eje X"); cy = listar_y_elegir(v_num, "Eje Y")
                cg = listar_y_elegir(cols_color, "Color (Grupo)")
                
                df_temp = df_full.copy()
                if cg in df_clean.columns: 
                    df_temp[cg] = df_clean[cg] # <---  df_clean
                graficar_estilo_premium(df_temp, cx, cy, col_grupo=cg, estilo=3)
            
            elif "Boxplot" in opcion:
                cols_cat_orig = [c for c in df_clean.columns if c in v_cat]
                cx = listar_y_elegir(cols_cat_orig, "Categórica (Eje X)")
                cy = listar_y_elegir(["probabilidad_voto", "imagen_candidato", "edad"], "Numérica (Eje Y)")
                
                df_temp = df_full.copy()
                df_temp[cx] = df_clean[cx] # <--- CAMBIO CLAVE: df_clean
                graficar_estilo_premium(df_temp, cx, cy, estilo=4)
            
            elif "Barras" in opcion:
                cols_cat_orig = [c for c in df_clean.columns if c in v_cat]
                cx = listar_y_elegir(cols_cat_orig, "Grupos (Eje X)")
                cy = listar_y_elegir(["probabilidad_voto", "imagen_candidato"], "Promedio de (Eje Y)")
                
                df_temp = df_full.copy()
                df_temp[cx] = df_clean[cx] # <--- CAMBIO CLAVE: df_clean
                graficar_estilo_premium(df_temp, cx, cy, estilo=5)

                df_temp = df_full.copy()
                df_temp[cx] = df_raw[cx]
                graficar_estilo_premium(df_temp, cx, cy, estilo=5)
            
            elif "Líneas" in opcion:                                                                 #(Técnicamente una regresión no paramétrica muy simple)
                cx = listar_y_elegir(["edad", "integrantes_h"], "Variable Continua (Eje X)")
                cy = listar_y_elegir(["probabilidad_voto", "imagen_candidato"], "Variable (Eje Y)")    #Y(x)=promedio de todos los Y donde la variable X = x
                graficar_estilo_premium(df_full, cx, cy, estilo=6)

            
            if "MAPA" in opcion:  # Verificamos que la variable exista y tenga datos
                if 'gdf_argentina' in locals() and gdf_argentina is not None:
                    
                lista_vip = [col_target, "probabilidad_voto"]
                    
                resto = [c for c in vars_disp if df_full[c].dtype != 'object' and c not in lista_vip]
                    
                opciones_mapa = lista_vip + resto                     #Unimos las listas para el menú

                col = listar_y_elegir(opciones_mapa, "Variable para el mapa")
                graficar_estilo_premium(df_full, col, estilo=7, gdf_mapa=gdf_argentina)
            else:
                    print("Error: No se cargó el mapa (variable gdf_argentina vacía).")

    except Exception as e:
        print(f"\n Error Inesperado: {e}")

